import logging
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from transformers import pipeline
from fastapi.middleware.cors import CORSMiddleware
import torch

# 1. Setup Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Toxicity Guardian API", version="2.0.0")
print("\n\n ðŸš€ NEW CODE LOADED: BLACKLIST ACTIVE! ðŸš€ \n\n")

# 2. CORS Security
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["POST"],
    allow_headers=["*"],
)

# 3. Load Multilingual AI Model (Hinglish/Hindi/English)
MODEL_NAME = "unitary/multilingual-toxic-xlm-roberta"
logger.info(f"Loading {MODEL_NAME}... this may take a moment.")

try:
    device = 0 if torch.cuda.is_available() else -1
    classifier = pipeline("text-classification", model=MODEL_NAME, top_k=None, device=device)
    logger.info("âœ… Multilingual Model loaded successfully.")
except Exception as e:
    logger.error(f"âŒ Failed to load model: {e}")
    classifier = None

# ==============================================================================
# 4. MASSIVE HINGLISH & ENGLISH BLACKLIST (The "Instant Ban" List)
# ==============================================================================
HINGLISH_BLACKLIST = [
    # --- LEVEL 1: Common Insults (Hinglish) ---
    "pagal", "paagal", "gadha", "gadhha", "ullu", "bewakoof", "bewaquf",
    "nalayak", "nalla", "chapri", "chhapri", "chammak", "dhakkan", "lukkha",
    "fattu", "bhikari", "bikhari", "ganwar", "gavar", "dehati", "jahil",
    "bakwaas", "bakwas", "bekar", "ghatia", "ghatiya", "ganda", "gandi",
    "kuda", "kachra", "tatti", "potty", "hag", "hagga",

    # --- LEVEL 2: Animal Insults ---
    "kutta", "kute", "kuta", "kutte", "kutiya", "kutiyaa",
    "kamina", "kamine", "kaminay", "suar", "suwar", "janwar",
    "bhens", "bhains", "bandar", "langoor", "khota",

    # --- LEVEL 3: Severe Abuses (Cursing/Swearing) ---
    "saala", "sala", "saale", "saley", "haramkhor", "harami", "haraami",
    "chutiya", "chu", "chutye", "choot", "chut",
    "gandu", "gaandu", "gand", "gaand", "gandfata", "gandmra",
    "bhosdike", "bhosadike", "bsdk", "bhosda",
    "madarchod", "mc", "ma ki", "maa ki", "maderchod",
    "bhenchod", "bc", "behenchod", "behen ki",
    "lawde", "lavde", "laude", "loda", "lowda", "lund", "land",
    "randi", "rand", "randwa", "chinal", "raand",
    "hijra", "chakka", "meetha", "halala", "kafir",

    # --- LEVEL 4: Phrases & Sentences (Hinglish) ---
    "dimaag kharab", "dimag kharab", "khopdi", "bheja fry",
    "chup kar", "chup be", "shakal dekh", "aukat", "auqaat",
    "mar ja", "marja", "doob mar", "nikal", "dafa ho",
    "baap par", "baap pe", "teri maa", "teri behen",

    # --- LEVEL 5: English Common Toxic Words ---
    "idiot", "stupid", "dumb", "fool", "moron", "retard", "loser",
    "useless", "pathetic", "disgusting", "nonsense", "rubbish", "trash",
    "shut up", "get lost", "go to hell", "kill yourself", "kys",
    "fuck", "fucker", "fucking", "shit", "bullshit", "bitch", "bastard",
    "asshole", "dick", "pussy", "cunt", "whore", "slut", "rapist"
]

# MASSIVE HINDI (DEVANAGARI) LIST - 200+ Words
HINDI_BLACKLIST = [
    # --- Category 1: Intelligence & Competence ---
    "à¤ªà¤¾à¤—à¤²", "à¤ªà¤—à¤²à¤¾", "à¤¬à¥Œà¤°à¤¾", "à¤¸à¤¨à¤•à¥€", "à¤¸à¤ à¤¿à¤¯à¤¾", "à¤–à¤¿à¤¸à¤•à¤¾", "à¤¦à¤¿à¤®à¤¾à¤— à¤¸à¥‡ à¤ªà¥ˆà¤¦à¤²",
    "à¤¬à¥‡à¤µà¤•à¥‚à¤«", "à¤®à¥‚à¤°à¥à¤–", "à¤œà¤¾à¤¹à¤¿à¤²", "à¤—à¤‚à¤µà¤¾à¤°", "à¤…à¤¨à¤ªà¤¢à¤¼", "à¤¬à¥à¤¦à¥à¤§à¥‚", "à¤®à¤‚à¤¦à¤¬à¥à¤¦à¥à¤§à¤¿",
    "à¤—à¤§à¤¾", "à¤—à¤§à¥‡", "à¤‰à¤²à¥à¤²à¥‚", "à¤‰à¤²à¥à¤²à¥‚ à¤•à¤¾ à¤ªà¤Ÿà¥à¤ à¤¾", "à¤¬à¥ˆà¤² à¤¬à¥à¤¦à¥à¤§à¤¿", "à¤—à¥‹à¤¬à¤° à¤—à¤£à¥‡à¤¶",
    "à¤¨à¤¾à¤²à¤¾à¤¯à¤•", "à¤¨à¤¾à¤•à¤¾à¤®", "à¤¨à¤²à¥à¤²à¤¾", "à¤¨à¤¿à¤ à¤²à¥à¤²à¤¾", "à¤•à¤¾à¤®à¤šà¥‹à¤°", "à¤«à¤¾à¤²à¤¤à¥‚",
    "à¤¢à¤•à¥à¤•à¤¨", "à¤²à¥‹à¤²", "à¤šà¥‚à¤¤à¤¿à¤¯à¤¾", "à¤…à¤•à¤² à¤•à¥‡ à¤¦à¥à¤¶à¥à¤®à¤¨",

    # --- Category 2: Character & Integrity ---
    "à¤•à¤®à¥€à¤¨à¤¾", "à¤•à¤®à¥€à¤¨à¥‡", "à¤¹à¤°à¤¾à¤®à¤–à¥‹à¤°", "à¤¹à¤°à¤¾à¤®à¥€", "à¤¨à¥€à¤š", "à¤§à¥‚à¤°à¥à¤¤", "à¤ªà¤¾à¤ªà¥€",
    "à¤§à¥‹à¤–à¥‡à¤¬à¤¾à¤œ", "à¤®à¤•à¥à¤•à¤¾à¤°", "à¤à¥‚à¤ à¤¾", "à¤«à¤°à¥‡à¤¬à¥€", "à¤¦à¤²à¤¾à¤²", "à¤­à¤¡à¤¼à¤µà¤¾", "à¤•à¥à¤•à¤°à¥à¤®à¥€",
    "à¤¦à¥à¤·à¥à¤Ÿ", "à¤°à¤¾à¤•à¥à¤·à¤¸", "à¤¶à¥ˆà¤¤à¤¾à¤¨", "à¤¦à¤°à¤¿à¤‚à¤¦à¤¾", "à¤¹à¥ˆà¤µà¤¾à¤¨", "à¤œà¤²à¥à¤²à¤¾à¤¦",
    "à¤¬à¥‡à¤—à¥ˆà¤°à¤¤", "à¤¬à¥‡à¤¶à¤°à¥à¤®", "à¤¬à¥‡à¤¹à¤¯à¤¾", "à¤¨à¤®à¤•à¤¹à¤°à¤¾à¤®", "à¤—à¤¦à¥à¤¦à¤¾à¤°", "à¤•à¥à¤²à¤šà¥à¤›à¤¨à¥€",

    # --- Category 3: Class & Appearance (Slurs) ---
    "à¤›à¤ªà¤°à¥€", "à¤›à¤®à¤¿à¤¯", "à¤­à¤¿à¤–à¤¾à¤°à¥€", "à¤­à¥€à¤–", "à¤•à¤‚à¤œà¥‚à¤¸", "à¤®à¤•à¥à¤–à¥€à¤šà¥‚à¤¸",
    "à¤¦à¥‡à¤¹à¤¾à¤¤à¥€", "à¤¦à¥‡à¤¹à¤¾à¤¤à¥€ à¤—à¤µà¤¾à¤°", "à¤•à¤¾à¤²à¤¾", "à¤•à¤²à¥à¤†", "à¤®à¥‹à¤Ÿà¤¾", "à¤¹à¤¾à¤¥à¥€", "à¤¸à¤‚à¤¡à¤¾",
    "à¤Ÿà¤¿à¤¡à¥à¤¡à¥€", "à¤¸à¥‚à¤–à¤¾", "à¤¹à¤¡à¥à¤¡à¥€", "à¤¬à¥Œà¤¨à¤¾", 

    # --- Category 4: Filth & Disgust ---
    "à¤¬à¤•à¤µà¤¾à¤¸", "à¤¬à¥‡à¤•à¤¾à¤°", "à¤•à¤šà¤°à¤¾", "à¤•à¥‚à¤¡à¤¼à¤¾", "à¤—à¤‚à¤¦à¤¾", "à¤—à¤‚à¤¦à¥€", "à¤˜à¤Ÿà¤¿à¤¯à¤¾",
    "à¤¸à¤¡à¤¼à¤¾", "à¤¬à¤¦à¤¬à¥‚à¤¦à¤¾à¤°", "à¤•à¥€à¤¡à¤¼à¤¾", "à¤¨à¤¾à¤²à¥€ à¤•à¤¾ à¤•à¥€à¤¡à¤¼à¤¾", "à¤—à¤‚à¤¦à¤—à¥€",
    "à¤Ÿà¤Ÿà¥à¤Ÿà¥€", "à¤—à¥‹à¤¬à¤°", "à¤¹à¤—", "à¤¹à¤—à¥à¤—à¤¾", "à¤®à¥‚à¤¤à¥à¤°", "à¤ªà¥‡à¤¶à¤¾à¤¬",

    # --- Category 5: Animals (Used as insults) ---
    "à¤•à¥à¤¤à¥à¤¤à¤¾", "à¤•à¥à¤¤à¥à¤¤à¥‡", "à¤•à¥à¤¤à¤¿à¤¯à¤¾", "à¤ªà¤¿à¤²à¥à¤²à¤¾", "à¤¸à¥‚à¤…à¤°", "à¤¸à¥à¤…à¤°", 
    "à¤œà¤¾à¤¨à¤µà¤°", "à¤­à¥‡à¤¡à¤¼à¤¿à¤¯à¤¾", "à¤¸à¤¾à¤‚à¤ª", "à¤¨à¥‡à¤µà¤²à¤¾", "à¤¬à¤‚à¤¦à¤°", "à¤²à¤‚à¤—à¥‚à¤°",
    "à¤­à¥ˆà¤‚à¤¸", "à¤—à¥‡à¤‚à¤¡à¤¾", "à¤–à¤šà¥à¤šà¤°",

    # --- Category 6: Severe Vulgarity (Body Parts/Acts) ---
    "à¤—à¤¾à¤‚à¤¡", "à¤—à¤¾à¤‚à¤¡à¥‚", "à¤—à¤¾à¤à¤¡", "à¤—à¤¾à¤£à¥à¤¡", "à¤ªà¤¿à¤›à¤µà¤¾à¤¡à¤¼à¤¾", "à¤šà¥‚à¤¤", "à¤šà¥‚à¤¤à¤¿à¤¯à¤¾", "à¤šà¥‚à¤¤à¤¿à¤¯à¥‡",
    "à¤­à¥‹à¤¸à¤¡à¤¼à¤¾", "à¤­à¥‹à¤¸à¤¡à¤¼à¥€", "à¤­à¥‹à¤¸à¤¡à¤¼à¥€à¤µà¤¾à¤²à¤¾", "à¤­à¥‹à¤¸à¤¡à¤¼à¥€à¤µà¤¾à¤²à¥‡", "à¤­à¥‹à¤¸à¤¡à¥€",
    "à¤²à¤‚à¤¡", "à¤²à¥Œà¤¡à¤¼à¤¾", "à¤²à¤µà¤¡à¤¾", "à¤²à¤¿à¤‚à¤—", "à¤à¤¾à¤‚à¤Ÿ", "à¤à¤¾à¤Ÿà¥‚", "à¤¬à¤¾à¤²",
    "à¤šà¥‹à¤¦", "à¤šà¥‹à¤¦à¥‚", "à¤šà¥‹à¤¦à¤¨à¤¾", "à¤šà¥à¤¦à¤¾à¤ˆ", "à¤®à¥à¤ à¤²", "à¤¹à¤¿à¤²à¤¾à¤¨à¥‡ à¤µà¤¾à¤²à¤¾",
    "à¤—à¤¾à¤‚à¤¡à¤®à¤°à¤¾", "à¤—à¤¾à¤‚à¤¡à¤«à¤Ÿà¤¾", "à¤šà¥‚à¤¤à¤¡à¤¼",

    # --- Category 7: Severe Abuses (Relations) ---
    "à¤®à¤¾à¤¦à¤°à¤šà¥‹à¤¦", "à¤®à¤¾à¤¦à¤°", "à¤®à¤¾à¤ à¤•à¥€", "à¤¤à¥‡à¤°à¥€ à¤®à¤¾à¤ à¤•à¥€",
    "à¤¬à¤¹à¤¨à¤šà¥‹à¤¦", "à¤¬à¥‡à¤¹à¤¨à¤šà¥‹à¤¦", "à¤¬à¤¹à¤¨ à¤•à¥€", "à¤¤à¥‡à¤°à¥€ à¤¬à¤¹à¤¨ à¤•à¥€",
    "à¤¬à¥‡à¤Ÿà¥€à¤šà¥‹à¤¦", "à¤¬à¤¾à¤ª à¤ªà¤° à¤®à¤¤ à¤œà¤¾", "à¤°à¤‚à¤¡à¥€", "à¤°à¤¨à¥à¤¡à¥€", "à¤›à¤¿à¤¨à¤¾à¤²à¤¾", "à¤›à¤¿à¤¨à¤¾à¤²",
    "à¤¤à¤µà¤¾à¤¯à¤«", "à¤•à¥‹à¤ à¥‡à¤µà¤¾à¤²à¥€", "à¤§à¤‚à¤§à¥‡à¤µà¤¾à¤²à¥€", "à¤¨à¤¾à¤œà¤¾à¤¯à¤œ", "à¤¹à¤°à¤¾à¤® à¤•à¥€ à¤”à¤²à¤¾à¤¦",

    # --- Category 8: Identity Slurs (Gender/Orientation) ---
    "à¤¹à¤¿à¤œà¤¡à¤¼à¤¾", "à¤›à¤•à¥à¤•à¤¾", "à¤®à¥€à¤ à¤¾", "à¤—à¥à¤¡à¤¼à¤¬à¤¾à¤œ", "à¤¨à¤¾à¤®à¤°à¥à¤¦", "à¤¨à¤ªà¥à¤‚à¤¸à¤•", 

    # --- Category 9: Violence & Threats ---
    "à¤¸à¤¾à¤²à¤¾", "à¤¸à¤¾à¤²à¥‡", "à¤¸à¤¾à¤²à¥€", "à¤®à¤° à¤œà¤¾", "à¤¦à¤«à¤¾ à¤¹à¥‹", "à¤¨à¤¿à¤•à¤²", "à¤­à¤¾à¤—",
    "à¤”à¤•à¤¾à¤¤", "à¤”à¤•à¤¾à¤¤ à¤®à¥‡à¤‚ à¤°à¤¹", "à¤¤à¥‡à¤°à¥€ à¤”à¤•à¤¾à¤¤", "à¤«à¥‹à¤¡à¤¼ à¤¦à¥‚à¤‚à¤—à¤¾", "à¤¤à¥‹à¤¡à¤¼ à¤¦à¥‚à¤‚à¤—à¤¾",
    "à¤œà¤¾à¤¨ à¤¸à¥‡ à¤®à¤¾à¤°", "à¤®à¤¾à¤° à¤¡à¤¾à¤²à¥‚à¤‚à¤—à¤¾", "à¤•à¤¾à¤Ÿ à¤¡à¤¾à¤²à¥‚à¤‚à¤—à¤¾", "à¤šà¥€à¤° à¤¦à¥‚à¤‚à¤—à¤¾", "à¤œà¤¿à¤‚à¤¦à¤¾ à¤œà¤²à¤¾",
    "à¤–à¥‚à¤¨ à¤ªà¥€ à¤œà¤¾à¤Šà¤‚à¤—à¤¾", "à¤Ÿà¤¾à¤‚à¤— à¤¤à¥‹à¤¡à¤¼", "à¤®à¥à¤‚à¤¹ à¤¤à¥‹à¤¡à¤¼", "à¤¥à¥‹à¤¬à¤¡à¤¼à¤¾"
]

class AnalysisRequest(BaseModel):
    text: str
    threshold: float = 0.05  # Very sensitive AI threshold

@app.get("/health")
def health_check():
    return {"status": "active", "model": MODEL_NAME}

@app.post("/analyze")
async def analyze_text(request: AnalysisRequest):
    if not classifier:
        raise HTTPException(status_code=500, detail="Model not loaded")

    # 1. Clean the text for checking
    text_lower = request.text.lower()
    
    # 2. CHECK BLACKLIST FIRST (Instant Ban)
    for bad_word in HINGLISH_BLACKLIST:
        # We check if the bad word is "in" the text. 
        # For better accuracy, we can check word boundaries, but simple 'in' works for now.
        if bad_word in text_lower:
            print(f"ðŸš« BLOCKED by Blacklist: Found '{bad_word}' in '{request.text[:20]}...'")
            return {
                "is_toxic": True,
                "categories": ["insult (manual blocklist)"]
            }

    # 3. IF SAFE FROM BLACKLIST, CHECK AI
    try:
        safe_text = request.text[:2000]
        results = classifier(safe_text)[0]

        toxic_categories = []
        is_toxic = False

        print(f"\nðŸ§ AI Analyzing: '{safe_text[:30]}...'")
        for res in results:
            print(f"   -> Label: {res['label']}, Score: {res['score']:.4f}")
            
            # If AI is confident it's toxic
            if res['label'] != 'neutral' and res['score'] >= request.threshold:
                toxic_categories.append(res['label'])
                is_toxic = True
        
        print(f"   => AI VERDICT: {'TOXIC ðŸ”´' if is_toxic else 'SAFE ðŸŸ¢'}")

        return {
            "is_toxic": is_toxic,
            "categories": toxic_categories
        }

    except Exception as e:
        logger.error(f"Prediction Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))